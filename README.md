### Here I impelement some of the basic machine learning methods from scratch.

## This repo is labled as <u>***TP***</u> \*Training Purposes\*
=================================================
# Projects:

### --- **warm-up practice.ipynb:**
- Create a 3D plot
- Solving normal equations
___
### --- **House Price Prediction with LOWESS and simple Gradient Descent:**
- Implementation of Locally Weighted Scatter Smoothing.
- Basic implementation of gradient descent with MSE loss function.
- House pirce prediction with above regression algorithms.
___
### --- **regularization methods.ipynb**:

*Different Regularization Methods in Polynomial Regression and Logistic Regression Classification.*
- Polynomial Regression
- Ridge Regression (L2 Regularization)
- Lasso Regression (L1 Regularization)
- Logistic Regression
---
### --- **one-layer softmax classifier on mnist.ipynb:**

*One-Layer Softmax Classifier with L2 Regularization on MNIST from Scratch.*
- Visualization
- Preprocessing
- Prediction with Random Normal Parameters
- Building a Softmax Classifier from ground up
- Results of Test Set
---
### --- **general two-layer nn classifier on mnist.ipynb**
*General Two-Layer Neural Network Classifer from scratch with ReLU Activation Function and Cross-Entropy Loss function On MNIST Dataset.*
-  Part 1: Implementation of Two-Layer Neural Network Classifier on MNIST Datset from Ground Up
    1. Data Loading
    2. Preprocessing
    3. Compose TwoLayerNeuralNetworkModule Class
    4. Training
    5. Results and Visualization
-  Part 2: Building a Neural Network Classifier with Sklearn Package